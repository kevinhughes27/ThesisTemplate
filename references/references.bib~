//////////////////////////////////
Introduction Refs

@article{mccahill2002cctv,
  title={CCTV in London},
  author={McCahill, Michael and Norris, Clive},
  journal={Report deliverable of UrbanEye project},
  year={2002}
}

	Estimate for how many cameras are in London UK

@article{said1990,
	title={DYCAM Model 1: The first portable Digital Still Camera},
	author={Carolyn Said},
	journal={MacWeek},
	year={1990},
	month={oct},
}

	Invention of digital camera

@ONLINE{eetAsia2004,
	title={Camera phones now majority of phone sales},
	year={2004},
	month={dec},
	url={http://www.eetasia.com/ART_8800353398_499488_NT_85fffae0.HTM},
}

@article{economist2010,
	title={Camera-phones Dotty but dashing},
	journal={The Economist},
	year={2010},
	month={apr},
	url={http://www.economist.com/node/15865270},
}

	more than a billion camera phones

@article{wallstreet2011,
	title={Camcorder Popular With Surfers Looks to Ride Professional Market},
	author={Nick Wingfield},
	journal={The Wall Street Journal},
	year={2011},
	month={apr},
}

	GoPro taking off

@ONLINE{youtube,
	title={Statistics},
	year={2013},
	month={feb},
	url={http://www.youtube.com/yt/press/statistics.html},
}

@ONLINE{facebook,
	title={3,000 Photos Are Uploaded Every Second to Facebook},
	author={Michael Zhang},
	year={2012},
	month={feb},
	url={http://www.petapixel.com/2012/02/01/3000-photos-are-uploaded-every-second-to-facebook/},
}

@article{opencv,
    author = {Bradski, G.},
    citeulike-article-id = {2236121},
    journal = {Dr. Dobb's Journal of Software Tools},
    keywords = {bibtex-import},
    posted-at = {2008-01-15 19:21:54},
    priority = {4},
    title = {{The OpenCV Library}},
    year = {2000}
}

@ARTICLE{Hu2006, 
author={Weiming Hu and Xuejuan Xiao and Zhouyu Fu and Xie, D. and Tieniu Tan and Maybank, S.}, 
journal={Pattern Analysis and Machine Intelligence, IEEE Transactions on}, 
title={A system for learning statistical motion patterns}, 
year={2006}, 
month={sept. }, 
volume={28}, 
number={9}, 
pages={1450 -1464}, 
ISSN={0162-8828},}	

@INPROCEEDINGS{Basharat2008, 
author={Basharat, A. and Gritai, A. and Mubarak Shah}, 
booktitle={Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on}, 
title={Learning object motion patterns for anomaly detection and improved object detection}, 
year={2008}, 
month={june}, 
volume={}, 
number={}, 
pages={1 -8},  
ISSN={1063-6919},}

	Successful automated surveilance methods without understanding the objects being tracked. More details on
	method in the EventDetection/References/references.bib











////////////////////////////////
Background Subtraction Surveys

@INPROCEEDINGS{Piccardi2004, 
author={Piccardi, M.}, 
booktitle={Systems, Man and Cybernetics, 2004 IEEE International Conference on}, 
title={Background subtraction techniques: a review}, 
year={2004}, 
month={oct.}, 
volume={4}, 
number={}, 
pages={3099 - 3104 vol.4}, 
keywords={ background density estimation; background subtraction technique; object detection; spatial correlation; static cameras; feature extraction; image motion analysis; object detection;}, 
ISSN={1062-922X},}

    Good review and short explanation of the following classic techniques.    
    
    Running Gaussian average 
    Temporal median filter 
    Mixture of Gaussians 
    Kernel density estimation (KDE) 
    Sequential KD approximation 
    Seki - Cooccurence of image variations 
    Eigenbackgrounds
    
    Limited comparison but they make 2 points I agree with
        - They discuss how Seki is block based and thus has limited accuracy
        - They discuss how eigenbackground performance seems to be related to the quality of the training images - a disadvantage
            - They further note that initialization and training is not well discussed in the eigenbackground approaches with respect
              to how it works in application        


@ARTICLE{Radke2005, 
author={Radke, R.J. and Andra, S. and Al-Kofahi, O. and Roysam, B.}, 
journal={Image Processing, IEEE Transactions on}, 
title={Image change detection algorithms: a systematic survey}, 
year={2005}, 
month={march }, 
volume={14}, 
number={3}, 
pages={294 -307}, 
keywords={hypothesis testing;illumination invariance;image change detection algorithm;predictive model;shading model;significance testing;systematic survey;image classification;Algorithms;Animals;Artificial Intelligence;Data Collection;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Models, Biological;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Signal Processing, Computer-Assisted;Subtraction Technique;},  
ISSN={1057-7149},}

    Focus on change detection - this can be much different than background subtraction for example comparing 2 registered images of a retina
    taken 6 months apart to track disease progress. Some key concepts remain the same though and change detection may be more applicable
    to machine faults.
    
    Discuss pre proccessing, notably to mitigate illumination effects
    
    Discuss how to compare and evaluate these algorithms, propose some neat metrics based on TP, FP etc.


@INPROCEEDINGS{Parks2008, 
author={Parks, D.H. and Fels, S.S.}, 
booktitle={Advanced Video and Signal Based Surveillance, 2008. AVSS '08. IEEE Fifth International Conference on}, 
title={Evaluation of Background Subtraction Algorithms with Post-Processing}, 
year={2008}, 
month={sept.}, 
volume={}, 
number={}, 
pages={192 -199}, 
keywords={background subtraction algorithms;computer vision;foreground objects segmentation;video stream processing;computer vision;image segmentation;video signal processing;}, 
ISSN={},}

    Evaluation of several BGS methods. Writer of BGS lib.
    Running Gaussian Average
    GMM
    AGMM
    Aproximate Median Filtering
    Median
    Mediod
    Eigenbackground
    
    Talks about drawing the line between background models and post processing
    specifically with respect to wallflower
    
    Table of parameters for the algorithms - good starting point
    Good discussion of post-proccessing techniques to improve BG.


@inproceedings{Benezeth2008,
title={Review and evaluation of commonly-implemented background subtraction algorithms},
author={Benezeth, Y. and Jodoin, P.M. and Emile, B. and Laurent, H. and Rosenberger, C.},
booktitle={Pattern Recognition, 2008. ICPR 2008. 19th International Conference on},
pages={1--4},
year={2008},
organization={IEEE}
}

	Quick comparison between basic methods:
		Single Frame
		One Gaussian
		Kernal Density Estimation
		GMM
		Min, Max, Mac Inter Diff
		
	No Real Conclusion

@article{Bouwmans2009,
title = {Subspace Learning for Background Modeling: A Survey},
author = {Bouwmans, Thierry},
pages = {223-234},
journal = {Recent Patent On Computer Science},
volume = {2},
number = {3 },
year = {2009},
month = {Nov},}

    Survey of subspace learning techniques for background subtraction.


@INPROCEEDINGS{Brutzer2011,
author = { Brutzer, Sebastian and Höferlin, Benjamin and Heidemann, Gunther },
title = { Evaluation of Background Subtraction Techniques for Video Surveillance },
year = { 2011 },
booktitle = { Computer Vision and Pattern Recognition (CVPR) },
pages = { 1937--1944 },
publisher = { IEEE }
}

    More recent evaluation of BGS techniques, main contribution is a synthetic but realistic data set for several important cases each with a 
    high quality ground truth. They also provide a matlab frame work for analyzing the results obtained on their video set.

	Algs tested:
	McFarlane - median
	Stauffer - GMM
	Oliver - eigenbackground
	McKenna - Gaussian
	Li - non-parametric discretized
	Kim - code word, multimodal

    It appears that they found source code for most the algorithms they tested on author's websites. Links are in the paper.
    
@inproceedings{Goyette2012,
  title={Changedetection. net: A new change detection benchmark dataset},
  author={Goyette, N. and Jodoin, P. and Porikli, F. and Konrad, J. and Ishwar, P.},
  booktitle={Computer Vision and Pattern Recognition Workshops (CVPRW), 2012 IEEE Computer Society Conference on},
  pages={1--8},
  year={2012},
  organization={IEEE},}
  
  the paper to cite for changedetection data set  
    
    






/////////////////////////////
Learning Uni-modal BGS

@inproceedings{lo2001automatic,
  title={Automatic congestion detection system for underground platforms},
  author={Lo, BPL and Velastin, SA},
  booktitle={Intelligent Multimedia, Video and Speech Processing, 2001. Proceedings of 2001 International Symposium on},
  pages={158--161},
  year={2001},
  organization={IEEE}
}

@article{el2007outdoor,
  title={Outdoor infrared video surveillance: A novel dynamic technique for the subtraction of a changing background of IR images},
  author={El Maadi, Amar and Maldague, Xavier},
  journal={Infrared physics \& technology},
  volume={49},
  number={3},
  pages={261--265},
  year={2007},
  publisher={Elsevier}
}

@article{abbott2009multiple,
  title={Multiple target tracking with lazy background subtraction and connected components analysis},
  author={Abbott, Robert G and Williams, Lance R},
  journal={Machine Vision and Applications},
  volume={20},
  number={2},
  pages={93--101},
  year={2009},
  publisher={Springer}
}

@article{shoushtarian2005practical,
  title={A practical adaptive approach for dynamic background subtraction using an invariant colour model and object tracking},
  author={Shoushtarian, Bijan and Bez, Helmut E},
  journal={Pattern Recognition Letters},
  volume={26},
  number={1},
  pages={5--26},
  year={2005},
  publisher={Elsevier}
}

@article{koller1994robust,
  title={Robust multiple car tracking with occlusion reasoning},
  author={Koller, Dieter and Weber, Joseph and Malik, Jitendra},
  journal={Computer Vision—ECCV'94},
  pages={189--196},
  year={1994},
  publisher={Springer}
}

@inproceedings{koller1994towards,
  title={Towards robust automatic traffic scene analysis in real-time},
  author={Koller, Dieter and Weber, J and Huang, T and Malik, J and Ogasawara, G and Rao, B and Russell, S},
  booktitle={Pattern Recognition, 1994. Vol. 1-Conference A: Computer Vision \& Image Processing., Proceedings of the 12th IAPR International Conference on},
  volume={1},
  pages={126--131},
  year={1994},
  organization={IEEE}
}

@article{davis2007background,
  title={Background-subtraction in thermal imagery using contour saliency},
  author={Davis, James W and Sharma, Vinay},
  journal={International Journal of Computer Vision},
  volume={71},
  number={2},
  pages={161--181},
  year={2007},
  publisher={Springer}
}

@inproceedings{jacques2005background,
  title={Background subtraction and shadow detection in grayscale video sequences},
  author={Jacques, J Cezar Silveira and Jung, Claudio Rosito and Musse, Soraia Raupp},
  booktitle={Computer Graphics and Image Processing, 2005. SIBGRAPI 2005. 18th Brazilian Symposium on},
  pages={189--196},
  year={2005},
  organization={IEEE}
}

@article{elgammal2003efficient,
  title={Efficient kernel density estimation using the fast gauss transform with applications to color modeling and tracking},
  author={Elgammal, Ahmed and Duraiswami, Ramani and Davis, Larry S},
  journal={Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  volume={25},
  number={11},
  pages={1499--1504},
  year={2003},
  publisher={IEEE}
}

@article{mckenna2000tracking,
  title={Tracking groups of people},
  author={McKenna, Stephen J and Jabri, Sumer and Duric, Zoran and Rosenfeld, Azriel and Wechsler, Harry},
  journal={Computer Vision and Image Understanding},
  volume={80},
  number={1},
  pages={42--56},
  year={2000},
  publisher={Elsevier}
}

@inproceedings{cezar2006background,
  title={A background subtraction model adapted to illumination changes},
  author={Cezar Silveira Jacques, J and Rosito Jung, C and Musse, Soraia Raupp},
  booktitle={Image Processing, 2006 IEEE International Conference on},
  pages={1817--1820},
  year={2006},
  organization={IEEE}
}

@article{davis2004robust,
  title={Robust background-subtraction for person detection in thermal imagery},
  author={Davis, J and Sharma, Vinay},
  journal={IEEE Int. Wkshp. on Object Tracking and Classification Beyond the Visible Spectrum},
  year={2004}
}

@article{jung2009efficient,
  title={Efficient background subtraction and shadow removal for monochromatic video sequences},
  author={Jung, Cl{\'a}udio Rosito},
  journal={Multimedia, IEEE Transactions on},
  volume={11},
  number={3},
  pages={571--577},
  year={2009},
  publisher={IEEE}
}

@inproceedings{gutchess2001background,
  title={A background model initialization algorithm for video surveillance},
  author={Gutchess, Daniel and Trajkovics, M and Cohen-Solal, Eric and Lyons, Damian and Jain, Anil K.},
  booktitle={Computer Vision, 2001. ICCV 2001. Proceedings. Eighth IEEE International Conference on},
  volume={1},
  pages={733--740},
  year={2001},
  organization={IEEE}
}

	Neat paper, focues on initilization and is a good citation for how many don't focus enough on this
	issue. May be able to take some ideas to improve my init alg.

@article{haritaoglu2000w,
  title={W< sup> 4</sup>: real-time surveillance of people and their activities},
  author={Haritaoglu, Ismail and Harwood, David and Davis, Larry S.},
  journal={Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  volume={22},
  number={8},
  pages={809--830},
  year={2000},
  publisher={IEEE}
}

@article{wu2010spatio,
  title={Spatio-temporal context for codebook-based dynamic background subtraction},
  author={Wu, Mingjun and Peng, Xianrong},
  journal={AEU-International Journal of Electronics and Communications},
  volume={64},
  number={8},
  pages={739--747},
  year={2010},
  publisher={Elsevier}
}

﻿@article {McFarlane1995,
author = {McFarlane, N. J. B. and Schofield, C. P.},
affiliation = {Silsoe Research Institute Wrest Park MK45 4HS Silsoe Bedford UK},
title = {Segmentation and tracking of piglets in images},
journal = {Machine Vision and Applications},
publisher = {Springer Berlin / Heidelberg},
issn = {0932-8092},
keyword = {Computer Science},
pages = {187-193},
volume = {8},
issue = {3},
year = {1995}}

    Adaptive Median Background Model
    Median chosen over mean because of its better rejection of outliers. Used Masked update. Used a thresholded laplacian on the original frame
    to improve segementation of objects that overlapped.
    Paper continues to have a description of their tracking system including updating with new objects.

@inproceedings{Ridder1995,
  title={Adaptive background estimation and foreground detection using kalman-filtering},
  author={Ridder, C. and Munkelt, O. and Kirchner, H.},
  booktitle={Proceedings of International Conference on recent Advances in Mechatronics},
  pages={193--199},
  year={1995},
  organization={Citeseer}}
  
  Background subtraction using Kalman Filters

@ARTICLE{Wren1997, 
author={Wren, C.R. and Azarbayejani, A. and Darrell, T. and Pentland, A.P.}, 
journal={Pattern Analysis and Machine Intelligence, IEEE Transactions on}, 
title={Pfinder: real-time tracking of the human body}, 
year={1997}, 
month={jul}, 
volume={19}, 
number={7}, 
pages={780 -785}, 
keywords={2D representation;Pfinder;behavior interpretation;human body;low-bandwidth coding;multiclass statistical model;people tracking;real-time system;standard SGI Indy computer;video databases;wireless interfaces;image coding;image colour analysis;image representation;image segmentation;video signal processing;}, 
ISSN={0162-8828},}

    Simple Gaussian Average for the background model. Simple but effective, can respond to scene changes in several seconds which for their big 
    picture is okay. PFinder is a more high level system that tracks people and their appendages using blobs and contours.
    WrenGA in libBGS


@INPROCEEDINGS{Toyama1999, 
author={Toyama, K. and Krumm, J. and Brumitt, B. and Meyers, B.}, 
booktitle={Computer Vision, 1999. The Proceedings of the Seventh IEEE International Conference on}, 
title={Wallflower: principles and practice of background maintenance}, 
year={1999}, 
month={}, 
volume={1}, 
number={}, 
pages={255 -261 vol.1}, 
keywords={Wallflower;background maintenance;background subtraction;frame-level component;region-level component;video surveillance systems;motion estimation;surveillance;}, 
ISSN={},}

    Wallflower
    Pixel Level (Weiner Filter), Region Level and Frame level processing.
    They discuss where to draw the line between background subtraction and the higher level system. Conclude that the background modelling 
    algorithm should not try to extract the semantics of foreground objects on its own.


@ARTICLE{Kato2002, 
author={Kato, J. and Watanabe, T. and Joga, S. and Rittscher, J. and Blake, A.}, 
journal={Pattern Analysis and Machine Intelligence, IEEE Transactions on}, 
title={An HMM-based segmentation method for traffic monitoring movies}, 
year={2002}, 
month={sep}, 
volume={24}, 
number={9}, 
pages={ 1291 - 1296}, 
keywords={HMM-based segmentation method;background objects;foreground;image classification;real-time system;robust visual tracking;shadows;traffic monitoring movies;computerised monitoring;hidden Markov models;image classification;image segmentation;road traffic;tracking;traffic engineering computing;},  
ISSN={0162-8828},}

    Use a 1D HMM for each pixel. The HMM takes into account temporal continuity when performing segmentation. Able to run real time and results 
    seem good. The paper contains references for other more machine learning based approaches to background subtraction.


@ARTICLE{Cucchiara2003, 
author={Cucchiara, R. and Grana, C. and Piccardi, M. and Prati, A.}, 
journal={Pattern Analysis and Machine Intelligence, IEEE Transactions on}, 
title={Detecting moving objects, ghosts, and shadows in video streams}, 
year={2003}, 
month={oct.}, 
volume={25}, 
number={10}, 
pages={ 1337 - 1342}, 
keywords={ apparent objects; background modeling; background subtraction methods; background update; color information; color segmentation; ghosts; human motion capture; moving object detection; object segmentation; object-based selective update; object-level knowledge; pixel processing; shadow detection; statistical assumptions; traffic monitoring; video streams; video surveillance; image motion analysis; image segmentation; object detection;},  
ISSN={0162-8828},}

    PratiMediod in libBGS
    Goal is to limit false negatives (not detecting foreground when you should) and use higher level feedback to avoid the other common issues.
    Chart on the validation rules for the feedback system. They use a selective optical flow feature for decision when neccesary.


@inproceedings{Li2003,
author = {Li, Liyuan and Huang, Weimin and Gu, Irene Y. H. and Tian, Qi},
title = {Foreground object detection from videos containing complex background},
booktitle = {Proceedings of the eleventh ACM international conference on Multimedia},
year = {2003},
isbn = {1-58113-722-2},
location = {Berkeley, CA, USA},
pages = {2--10},
numpages = {9},
acmid = {957017},
publisher = {ACM},
address = {New York, NY, USA},
keywords = {Bayes model, background modeling, color co-occurrence, foreground segmentation, video processing, video surveillance},}

    Background subtraction using a Bayes Decision Rule.
    They use a running background model and an instananeous frame difference to classify at each step. More of a higher level
    feature based approach to background subtraction.


@article{Kim2005,
author = "Kyungnam Kim and Thanarat H. Chalidabhongse and David Harwood and Larry Davis",
title = "Real-time foreground–background segmentation using codebook model",
journal = "Real-Time Imaging",
volume = "11",
number = "3",
pages = "172 - 185",
year = "2005",
issn = "1077-2014",}

    Background subtraction using codebook model
    Sort of an object oriented approach, each pixel has a codebook which is filled with codewords.
    Each code work contains, RGB, max, min, frequency it has been observed and last time observed.
    Pixels are matched to codewords if there isn't a match it is foreground, old code words are discarded.
    

@inproceedings{Calderara2006,
author = {Calderara, Simone and Melli, Rudy and Prati, Andrea and Cucchiara, Rita},
title = {Reliable background suppression for complex scenes},
booktitle = {Proceedings of the 4th ACM international workshop on Video surveillance and sensor networks},
series = {VSSN '06},
year = {2006},
isbn = {1-59593-496-0},
location = {Santa Barbara, California, USA},
pages = {211--214},
numpages = {4},
acmid = {1178814},
publisher = {ACM},
address = {New York, NY, USA},
keywords = {background suppression, people detection and tracking, shadow detection},}

    PratiMediod in libBGS
    Entry in VSSN'06 Background subtraction contest.
    Circular Buffer for Temporal Median.
    Low and High threshold approach.
    Propose a high level feedback system for quick ghost suppression.


@ARTICLE{Heikkila2006, 
author={Heikkila, M. and Pietikainen, M.}, 
journal={Pattern Analysis and Machine Intelligence, IEEE Transactions on}, 
title={A texture-based method for modeling the background and detecting moving objects}, 
year={2006}, 
month={april }, 
volume={28}, 
number={4}, 
pages={657 -662}, 
keywords={adaptive local binary pattern histograms;background modeling;moving object detection;texture-based method;video sequence;image sequences;image texture;motion estimation;object detection;video signal processing;Algorithms;Artificial Intelligence;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Models, Biological;Movement;Pattern Recognition, Automated;Photography;Reproducibility of Results;Sensitivity and Specificity;Subtraction Technique;Video Recording;},  
ISSN={0162-8828},}

    Use LBP (Local Binary Patterns)
        * Robust to illumination changes
        * Don't perform well on flat or boring regions, think uniform sky
        * LBPs also work for facial recognition, implemented by Phillip in libfacerec
        * Sort of like a feature for a single pixel?
        * Fast to compute
    
    They maintain several models for each pixel and perform GMM style updating to the models.


@article{WangH2007,
title = "A consensus-based method for tracking: Modelling background scenario and foreground appearance",
journal = "Pattern Recognition",
volume = "40",
number = "3",
pages = "1091 - 1105",
year = "2007",
note = "",
issn = "0031-3203",
author = "Hanzi Wang and David Suter",
keywords = "Background modelling",
keywords = "Background subtraction",
keywords = "Sample consensus",
keywords = "Visual tracking",
keywords = "Segmentation",
keywords = "Foreground appearance modelling",
keywords = "Occlusion"}

    Maintain a cache of N frames, classify the current pixel based on the consensus with the stored pixels.
    Update at pixel and blob level
    If enough of the past pixels agree it is marked background. 
    Use normalized chromacity coordinates to minimize effects of brightness changes
    
    Also includes a system for tracking people w/ occlusion
        

﻿@incollection{Pilet2008,
author = {Pilet, Julien and Strecha, Christoph and Fua, Pascal},
affiliation = {École Polytechnique Fédérale de Lausanne Switzerland},
title = {Making Background Subtraction Robust to Sudden Illumination Changes},
booktitle = {Computer Vision – ECCV 2008},
series = {Lecture Notes in Computer Science},
editor = {Forsyth, David and Torr, Philip and Zisserman, Andrew},
publisher = {Springer Berlin / Heidelberg},
isbn = {978-3-540-88692-1},
keyword = {Computer Science},
pages = {567-580},
volume = {5305},
year = {2008},}

    A complicated technique which models background and foreground as GMMs and adding texture features to the mixture model.
    Their technique includes modeling illumination
    As the title indicates their technique is robust to illumination changes.

@inproceedings{li2003foreground,
  title={Foreground object detection from videos containing complex background},
  author={Li, Liyuan and Huang, Weimin and Gu, Irene YH and Tian, Qi},
  booktitle={Proceedings of the eleventh ACM international conference on Multimedia},
  pages={2--10},
  year={2003},
  organization={ACM}
}








////////////////////////////////
Background Subtraction GMM

@INPROCEEDINGS{Stauffer1999, 
author={Stauffer, C. and Grimson, W.E.L.}, 
booktitle={Computer Vision and Pattern Recognition, 1999. IEEE Computer Society Conference on.}, 
title={Adaptive background mixture models for real-time tracking}, 
year={1999}, 
month={}, 
volume={2}, 
number={},  
keywords={adaptive background mixture models;background subtraction;image sequences;real-time segmentation;real-time tracking;thresholding;image segmentation;image sequences;real-time systems;tracking;},  
ISSN={},}

    Original Gaussian Mixture Model for background subtraction


@INPROCEEDINGS{Kaewtrakulpong2001,
author = {P. Kaewtrakulpong and R. Bowden},
title = {An Improved Adaptive Background Mixture Model for Realtime Tracking with Shadow Detection},
year = {2001},}

    The paper for the opencv BackgroundSubtractorMOG algorithm
    Slight update to Stauffer and Grimson, fixes an initialization issue where the original GMM may take a long time to
    adjust to a foreground object present at initialization. They also propose some type of shadow detection.


@inproceedings{Power2002,
title={Understanding background mixture models for foreground segmentation},
author={Power, P.W. and Schoonees, J.A.},
booktitle={Proceedings image and vision computing New Zealand},
volume={2002},
year={2002}}

    A tutorial paper on how to implement GMM (says original papers lack full detail that an implementation requires)
    

@inproceedings{Zivk2004,
author={Z.Zivkovic},
title={Improved adaptive Gausian mixture model for background subtraction},
booktitle={Proceedings of the International Conference on Pattern Recognition},
year={2004},}

    State of the art GMM background subtraction.
    Main difference is the dynamic management of the number of gaussians for a certain pixel.
    Performance isn't always better than Stauffer and Grimson though.

@article{lee2005effective,
  title={Effective Gaussian mixture learning for video background subtraction},
  author={Lee, Dar-Shyang},
  journal={Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  volume={27},
  number={5},
  pages={827--832},
  year={2005},
  publisher={IEEE}
}

﻿@incollection {Poppe2007,
author = {Poppe, Chris and Martens, Gaëtan and Lambert, Peter and Van de Walle, Rik},
affiliation = {Ghent University - IBBT, Department of Electronics and Information Systems - Multimedia Lab, Gaston Crommenlaan 8, B-9050 Ledeberg-Ghent Belgium},
title = {Improved Background Mixture Models for Video Surveillance Applications},
booktitle = {Computer Vision – ACCV 2007},
series = {Lecture Notes in Computer Science},
editor = {Yagi, Yasushi and Kang, Sing and Kweon, In and Zha, Hongbin},
publisher = {Springer Berlin / Heidelberg},
isbn = {978-3-540-76385-7},
keyword = {Computer Science},
pages = {251-260},
volume = {4843},
year = {2007}}

    Update to the standard GMM technique to improve performance with regards to illumination changes. 

    The original GMM typically has a small learning rate so quick changes take a while to be "learned". The authors note that most illumination 
    changes result in only small differences between pixel values in consecutive frames. They then update the GMM update algorithm to exploit 
    this observation. 

    Better results than standard GMM.

@INPROCEEDINGS{Zang2004, 
author={Qi Zang and Klette, R.}, 
booktitle={Pattern Recognition, 2004. ICPR 2004. Proceedings of the 17th International Conference on}, 
title={Robust background subtraction and maintenance}, 
year={2004}, 
month={aug.}, 
volume={2}, 
number={}, 
pages={ 90 - 93 Vol.2}, 
keywords={ Gaussian mixture; object extraction; robust background subtraction; stationary camera; Gaussian processes; feature extraction; image motion analysis;},  
ISSN={1051-4651 },}

    GMMs extended to region and frame level. Good overview of other GMM methods.
    They use simple frame differencing to clean up the pixel level result.
    Then they use an interesting morpholigcal like operatore to remove noise and "fill holes"   





@article{Barnich2011,
title = {{ViBe}: A universal background subtraction algorithm for video sequences},
author = {O. Barnich and M. {Van Droogenbroeck}},
journal = {IEEE Transactions on Image Processing},
volume = {20},
number = {6},
pages = {1709-1724},
month = {June},
year = {2011},
keywords = {ViBe, Background, Background subtraction, Segmentation, Motion, Motion detection},}

    ViBe Background subtraction, state of the art. High performing on CVPR changedetection contest.
    
    Good/Complete literature review/background section. (the greatness of this section can possibly be attributed to the authors wanting to
    backup their claim that their technique is the best).
    
    Background subtraction techniques have to deal with at least three considerations in order to be successful in real applications: 
    1) what is the model and how does it behave? 
    2) how is the model initialized? and 
    3) how is the model updated over time?
    
    They question the validity of the assumptions behind the common statistical techniques.
    Their technique can be initialized from a single frame - this allows them to do something interesting - rather than store several models
    of the background for different lighting and use frame level processing to trigger a model switch they instead are able to simply regen the
    background whenever they detect that a lighting change has occured.
    
    They initialize a temporal history of a pixel by drawing from nearby pixels (spatial).
    
    Good discussion of update policies 
        - Conservative Update - Never Learn pixels classified as foreground into the model - issues: everlasting ghosts, never fixing miss 
        classified pixels
        - Blind Update - Update all pixels regardless of classification - issues: poor detection of slow moving or stopped objects
    
    For their history model of each pixel rather than a first-in-first-out policy the authors discard a sample at random to make space fo
    the new value, They also apply random updating so that a pixel is not updated each iteration
    
    "regional diffusion"
    
    They use a Conservative Update scheme and to tacke the problem of everlasting ghosts they employ an interesting idea. The typical solution is 
    to count how long a foreground object has been present and then to incorportate it into the background at some point. Their strategy is 
    similar only they don't incorporate from the object present but rather from its spatial neighbours.
    
    Interesting performance metric PCC - combines TP,FP,TN,FN
    
    ViBe is fast (uses only integer computations) suitable for embedded systems.
    
    Psuedo Code in the Appendix
    










///////////////////////////
BGS MultModal Non-GMM
        
@inproceedings{Hofmann2012,
title={Background Segmentation with Feedback: The Pixel-Based Adaptive Segmenter},
author={Martin Hofmann, Philipp Tiefenbacher, Gerhard Rigoll},
booktitle={IEEE Workshop on Change Detection},
year={2012},}

    PBAS, currently the top algorithm in CVPR 2012 change detection contest

    Background model is a history of the last N values at each pixel location. Classification is done through concensus
    i.e. background if close to at least 5 history points
    
    They also do not update all the time but instead update at a certain probability each step. With another probability they also update a pixel
    with the value of its neighbor. Update is also conservate but their update process means that foreground objects will slowly be eaten from 
    the outside in.
    
    They measure the "dynamics" of the background by also storing the minimum distances found while running. Using this info they auto-tune
    thresholds for each pixel.
    
    They apply a new update law (modifying conservative update) which affects the rate at which the blob is "eaten" away at during update. 
    The desired result is to learn miss-classifications into the background but not learn slow moving objects. 
    The rate is based on the assumption that a miss-classification is more likely in the highly dynamic regions of the image and the size of the
    object.
    
    Full Source Code on their website.








////////////////////////////////
Eigen Analysis

@article{Pearson1901,
title={LIII. On lines and planes of closest fit to systems of points in space},
author={Pearson, K.},
journal={The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
volume={2},
number={11},
pages={559--572},
year={1901},
publisher={Taylor \& Francis}
}

	Inventor of PCA


@article{Pearson1901b,
title={Principal components analysis},
author={Pearson, K.},
journal={The London, Edinburgh and Dublin Philosophical Magazine and Journal},
volume={6},
number={2},
pages={566},
year={1901}
}
	
	Inventor of PCA


@article{Hotelling1933,
title={Analysis of a complex of statistical variables into principal components.},
author={Hotelling, H.},
journal={Journal of educational psychology},
volume={24},
number={6},
pages={417},
year={1933},
publisher={Warwick \& York}
}

	Canonical Correlation Analysis
	

﻿@article {Fischer1936,
author = {FISHER, R. A.},
title = {THE USE OF MULTIPLE MEASUREMENTS IN TAXONOMIC PROBLEMS},
journal = {Annals of Eugenics},
volume = {7},
number = {2},
publisher = {Blackwell Publishing Ltd},
issn = {2050-1439},
pages = {179--188},
year = {1936},
}

	Inventor of Linear Discriminant Analysis
	

@article{Ahmed1975,
  title={OrthogonalTransforms for Digital Signal Processing},
  author={Ahmed, A.M. and Day, D.D.},
  year={1975},
  publisher={Citeseer}
}

	Early summary of using PCA on images - cite this paper


@inproceedings{Rao1976,
  title={Orthogonal transforms for digital signal processing},
  author={Rao, K. and Ahmed, N.},
  booktitle={Acoustics, Speech, and Signal Processing, IEEE International Conference on ICASSP'76.},
  volume={1},
  pages={136--140},
  year={1976},
  organization={IEEE}
}

	same as above


@article{Lawton1971,
  title={Self modeling curve resolution},
  author={Lawton, W.H. and Sylvestre, E.A.},
  journal={Technometrics},
  volume={13},
  number={3},
  pages={617--633},
  year={1971},
  publisher={Taylor \& Francis Group}
}

	Pre-cursor to non-negative-matrix-factorization

@article{Sirovich1987, 
author = {L. Sirovich and M. Kirby}, 
journal = {J. Opt. Soc. Am. A}, 
keywords = {},
number = {3}, 
pages = {519--524}, 
publisher = {OSA},
title = {Low-dimensional procedure for the characterization of human faces}, 
volume = {4}, 
month = {Mar},
year = {1987},}

    First to apply PCA to images of faces. Experimented with the dimension of the "global" face space


@INPROCEEDINGS{Turk1991, 
author={Turk, M.A. and Pentland, A.P.}, 
booktitle={Computer Vision and Pattern Recognition, 1991. Proceedings CVPR '91., IEEE Computer Society Conference on}, 
title={Face recognition using eigenfaces}, 
year={1991}, 
month={jun}, 
volume={}, 
number={}, 
pages={586 -591}, 
keywords={eigenfaces;eigenvectors;face images;face recognition system;face space;feature space;human faces;two-dimensional recognition;unsupervised learning;computerised pattern recognition;eigenvalues and eigenfunctions;},  
ISSN={},}

    Turk and Pentland's Eigenface. Extended the work in Sirovich 1987 to include recognizing faces using the proximity of points in the 
    eigenspace.


@article{Comon1994,
  title={Independent component analysis, a new concept?},
  author={Comon, P.},
  journal={Signal processing},
  volume={36},
  number={3},
  pages={287--314},
  year={1994},
  publisher={Elsevier}
}

	First paper on ICA (was shown in a workshop in 1991)


﻿@article {Paatero1994,
author = {Paatero, Pentti and Tapper, Unto},
title = {Positive matrix factorization: A non-negative factor model with optimal utilization of error estimates of data values},
journal = {Environmetrics},
volume = {5},
number = {2},
publisher = {John Wiley & Sons, Ltd.},
issn = {1099-095X},
pages = {111--126},
year = {1994},
}

	Posetive Matrix Factorization (non-negative matrix factorization)

@techreport{Nayar1994,
title={Dimensionality of illumination manifolds in eigenspace},
author={Nayar, S.K. and Murase, H.},
year={1994},
institution={Citeseer}}

    This paper explores how many dimensions (in an eigenspace) are required to represent an object under different lighting conditions 
        

﻿@article {Murase1995,
author = {Murase, Hiroshi and Nayar, Shree K.},
affiliation = {NTT Basic Research Laboratory Atsugi-Shi 243-01 Kanagawa Japan},
title = {Visual learning and recognition of 3-d objects from appearance},
journal = {International Journal of Computer Vision},
publisher = {Springer Netherlands},
issn = {0920-5691},
keyword = {Computer Science},
pages = {5-24},
volume = {14},
issue = {1},
year = {1995}}

    Murase and Nayar "appearance based recognition" Placed an object on a turn table and took pictures at every 5 degrees. They also adjusted 
    the camera position vertically in a spherical fashion to capture all view points. They then took the PCA of this image set.
    They first introduced the concept of the manifold in eigenspace. With this idea they were able to recognize the pose of an object and 
    generate intermediate views (views in between the 5 degrees that were used to generate the space) which was quite neat.
    They use a universal space for recogntion and an object space.


@INPROCEEDINGS{Nayar1996, 
author={Nayar, S.K. and Nene, S.A. and Murase, H.}, 
booktitle={Robotics and Automation, 1996. Proceedings., 1996 IEEE International Conference on}, 
title={Real-time 100 object recognition system}, 
year={1996}, 
month={apr}, 
volume={3}, 
number={}, 
pages={2321 -2325 vol.3}, 
keywords={CCD color camera;appearance matching;image segmentation;object pose;object recognition system;real-time capability;real-time vision system;recognition loop;recognition rate;region normalizations;scene change detection;three-dimensional objects;workstation;image matching;image segmentation;object recognition;}, 
ISSN={},}

    Extension of Murase 1995 to include 100 objects
    
    
@INPROCEEDINGS{{Ohba1996, 
author={Ohba, K. and Ikeuchi, K.}, 
booktitle={Pattern Recognition, 1996., Proceedings of the 13th International Conference on}, 
title={Recognition of the multi-specularity objects using the eigen-window }, 
year={1996}, 
month={aug}, 
volume={1}, 
number={}, 
pages={692 -696 vol.1}, 
keywords={bin-picking tasks;computer vision;eigen-window method;eigenvalues;eigenvectors;image matching;memory space;multiple specularity object recognition;partially occluded objects;pose clustering;similarity measure;computer vision;eigenvalues and eigenfunctions;image matching;object recognition;},  
ISSN={},}

    Eigen-Window - essentially a sliding window version of Murase and Nayar's object recognition system. The PCA space is trained on a smaller 
    image and then patches of the full image are projected into this space.
    Their system could handle recognition of partially occluded objects. Another interesting application they briefly touch on is using small
    "eigen-windows" for corner detection.


@article{Black1996,
title={Eigentracking: Robust matching and tracking of articulated objects using a view-based representation},
author={Black, M. and Jepson, A.},
journal={Computer Vision—ECCV'96},
pages={329--342},
year={1996},
publisher={Springer}
}

	Eigentracking
	
	Robust reconstruction to avoid least square fit problems, they have an example similar to my PCA_Proof
	They discuss this idea of robust re-construction a lot, they have good examples and this might be useful for BGS
	Its focused on removing outliers from new samples not about having outliers in the PCA basis vectors
	
	A poor description of the tracking:
	They then use optical flow to find candidate objects, they then align them and subject it to the eigentracking


@article{Belhumeur1997,
title={Eigenfaces vs. fisherfaces: Recognition using class specific linear projection},
author={Belhumeur, P.N. and Hespanha, J.P. and Kriegman, D.J.},
journal={Pattern Analysis and Machine Intelligence, IEEE Transactions on},
volume={19},
number={7},
pages={711--720},
year={1997},
publisher={IEEE}
}

	Fischerface

@article{Zhao1998,
title = "Theoretical analysis of illumination in PCA-based vision systems",
journal = "Pattern Recognition",
volume = "32",
number = "4",
pages = "547 - 564",
year = "1999",
note = "",
issn = "0031-3203",
author = "Li Zhao and Yee-Hong Yang",
keywords = "Illumination effects",
keywords = "Interreflection",
keywords = "Light intensity change",
keywords = "Light sources",
keywords = "Mosaic image method",
keywords = "Principal component analysis",
keywords = "Radiosity method"}

    System to account for arbitrary illumination effects for a pose of an object in PCA-based vision systems.
    Method can be used to compress the image of the object in any possible illumination


@article{Zhao1999,
title={Mosaic image method: a local and global method},
author={Zhao, L. and Yang, Y.H.},
journal={Pattern Recognition},
volume={32},
number={8},
pages={1421--1433},
year={1999},
publisher={Citeseer}}

    An extension of Murase and Nayar's appearanced based object recogniton. They divide the image along a regular grid into smaller 
    mosaic images. PCA is performed on each mosaic image individually. They originally did this to account for occlusion but also
    found that mosaicing improved the detection performance in general.           


@article{lee1999,
  title={Learning the parts of objects by non-negative matrix factorization},
  author={Lee, D.D. and Seung, H.S. and others},
  journal={Nature},
  volume={401},
  number={6755},
  pages={788--791},
  year={1999},
  publisher={Nature Publishing Group, The Macmillan Building London N 1 9 XW United Kingdom}
}

	Non-Negative Matrix Factorization
	

@inproceedings{Torre2001,
title={Robust principal component analysis for computer vision},
author={De la Torre, F. and Black, M.J.},
booktitle={Computer Vision, 2001. ICCV 2001. Proceedings. Eighth IEEE International Conference on},
volume={1},
pages={362--369},
year={2001},
organization={IEEE}}

    RPCA
    
    Looks like it does an analysis on the data and tries to find statistical outliers then it lowers the weight on them
    for doing PCA
    

@article{Torre2003,
  title={A framework for robust subspace learning},
  author={De La Torre, F. and Black, M.J.},
  journal={International Journal of Computer Vision},
  volume={54},
  number={1},
  pages={117--142},
  year={2003},
  publisher={Springer}
}

	Extened version of Torre2001


@ARTICLE{weng2003ccipca, 
author={Juyang Weng and Yilu Zhang and Wey-Shiuan Hwang}, 
journal={Pattern Analysis and Machine Intelligence, IEEE Transactions on}, 
title={Candid covariance-free incremental principal component analysis}, 
year={2003}, 
month={aug.}, 
volume={25}, 
number={8}, 
pages={ 1034 - 1040}, 
keywords={ Gaussian distribution; appearance-based image analysis techniques; candid covariance-free IPCA; candid covariance-free incremental principal component analysis; cerebral cortex; covariance matrix; eigenvector; high-dimensional image vectors; image analysis; mean of observations; real-time applications; statistical efficiency; Gaussian distribution; covariance matrices; eigenvalues and eigenfunctions; image processing; principal component analysis; real-time systems;},  
ISSN={0162-8828},}

    CCIPCA Algorithm (Candid Covariance-Free Incremental PCA)
    Fast way for finding/estimating the eigenvectors of a high dimensional set when the data is streamed in rather than collected and analyzed 
    all at once.
    
    They basically calculate the left over variance of a new sample ("the residual") and put this vector as a new eigenvector which gets updated in the next iteration
    
    They have a clever way to test their results - they compare the eigenfaces they find after streaming the data to the eigenfaces found by a 
    batched PCA and make sure they are similar.
    
    They also have a space comparision here, dot products with the eigenvectors of the full batch PCA graphed with respect to the number of data input to IPCA


@inproceedings{Mairal2009,
title={Online dictionary learning for sparse coding},
author={Mairal, J. and Bach, F. and Ponce, J. and Sapiro, G.},
booktitle={Proceedings of the 26th Annual International Conference on Machine Learning},
pages={689--696},
year={2009},
organization={ACM}
}

	Online Dictionary Learning
	

@article{Candes2009,
  title={Robust principal component analysis?},
  author={Candes, E.J. and Li, X. and Ma, Y. and Wright, J.},
  journal={arXiv preprint arXiv:0912.3599},
  year={2009}
}

	Modern RPCA


@article{Bao2012,
title={Inductive Robust Principal Component Analysis},
author={Bao, B.K. and Liu, G. and Xu, C. and Yan, S.},
journal={Image Processing, IEEE Transactions on},
volume={21},
number={8},
pages={3794--3800},
year={2012},
publisher={IEEE}
}
	Modern RPCA, addresses a few shortcomings











///////////////////////////////////////////////
Background Subtraction Subspace

@ARTICLE{Oliver2000, 
author={Oliver, N.M. and Rosario, B. and Pentland, A.P.}, 
journal={Pattern Analysis and Machine Intelligence, IEEE Transactions on}, 
title={A Bayesian computer vision system for modeling human interactions }, 
year={2000}, 
month={aug}, 
volume={22}, 
number={8}, 
pages={831 -843}, 
keywords={Bayes method;computer vision;hidden Markov model;human behavior recognition;image segmentation;machine learning;pattern recognition;people detection;real-time systems;visual surveillance;Bayes methods;computer vision;hidden Markov models;image segmentation;learning systems;object recognition;real-time systems;surveillance;}, 
ISSN={0162-8828},} 

    Original Eigenbackground Paper. PCA space is created using several clean background images. Foreground is segmented by projecting the current 
    frame into the space and then reconstructing it. The reconstructed image is subtracted from the original image leaving only the foreground 
    objects behind.

    The paper continues on to describe a full human activity monitoring system that follows the typical routine of blob tracking followed by HMM.

    Is patented


@INPROCEEDINGS{Monnet2003, 
author={Monnet, A. and Mittal, A. and Paragios, N. and Visvanathan Ramesh}, 
booktitle={Computer Vision, 2003. Proceedings. Ninth IEEE International Conference on}, 
title={Background modeling and subtraction of dynamic scenes}, 
year={2003}, 
month={oct.}, 
volume={}, 
number={}, 
pages={1305 -1312 vol.2}, 
keywords={background modeling;background subtraction;computer vision;dynamic scenes;image detection;motion analysis;natural scenes;on-line auto-regressive model;perturbation;probabilistic representation;real-time video analysis;scene modeling;state-driven comparison;static background;static scene;static structure;waving trees;computer vision;feature extraction;image motion analysis;image representation;natural scenes;object detection;probability;}, 
doi={10.1109/ICCV.2003.1238641}, 
ISSN={},}

    Incremental PCA or IPCA background subtraction - essentially eigenbackground with update/learning
    
    They proccess the video in small blocks or tiles too, the detection scheme they employ is two fold
    they use distance of projection in eigenspace and recontruction error.


@inproceedings{Skocaj2002,
  title={Incremental approach to robust learning of eigenspaces},
  author={Skocaj, D. and Leonardis, A.},
  booktitle={Vision with non-traditional sensors, 26th Workshop of the Austrian Association for Pattern Recognition},
  pages={111--118},
  year={2002}
}

	Precursor


@inproceedings{Skocaj2003,
title={Weighted and robust incremental method for subspace learning},
author={Skocaj, D. and Leonardis, A.},
booktitle={Computer Vision, 2003. Proceedings. Ninth IEEE International Conference on},
pages={1494--1501},
year={2003},
organization={IEEE}
}
	This is a good paper
	
	Incremental wieghted update
	Might be easy to extend to by dynamically sized as the update adds a vectors sorts and then discards, could put a conidtion on the discard
	Has pseudo code
	They did a simple 2 experiement to show how their alg arrives at the same basis as the batch mode
	Their update uses the reconstruction before updating the basis to fill in missing or bad pixels in the input image before updating the basis
	Uses robust projection
	
	Discusses issues with respect to the quality of the initial eigenspace prior to begining updating
	This model is susceptable to the standard issues of "Hard" updating, can it be extended using the ideas from ViBe to get around this?
	
	Face experiement using ORL database (can I reproduce?)
	Test the quality of the space using the Mean Squared Reconstruction Errors MSRE


@INPROCEEDINGS{Seki2000, 
author={Seki, M. and Fujiwara, H. and Sumi, K.}, 
booktitle={Applications of Computer Vision, 2000, Fifth IEEE Workshop on.}, 
title={A robust background subtraction method for changing background}, 
year={2000}, 
month={}, 
volume={}, 
number={}, 
pages={207 -213}, 
keywords={Mahalanobis distances;background subtraction;changing background;eigenspace;moving objects;real world scenes;video images;eigenvalues and eigenfunctions;motion estimation;}, 
ISSN={},}

    Eigen-Blob background subtraction. Blobs are 8x8 sections and they overlap by 4. Results don't actually seem all that great
    and they notably don't compare against any of the 


@INPROCEEDINGS{Seki2003, 
author={Seki, M. and Wada, T. and Fujiwara, H. and Sumi, K.}, 
booktitle={Computer Vision and Pattern Recognition, 2003. Proceedings. 2003 IEEE Computer Society Conference on}, 
title={Background subtraction based on cooccurrence of image variations}, 
year={2003}, 
month={june}, 
volume={2}, 
number={}, 
pages={ II-65 - II-72 vol.2}, 
keywords={ background image variation; background subtraction; detection sensitivity; dynamic environment; dynamic scene; fluttering flag; foreground object detection; image updating; image variation cooccurrence; input image analysis; morphological postprocessing; neighboring image block correlation; swaying tree; image colour analysis; image morphing; image segmentation; object detection; variational techniques;},  
ISSN={1063-6919},}

    Cooccurrence extension of Eigen-Blob (a blob's classification as background or foreground depends on its neighbours classifications). 
    Again results are not all that impressive with the only main result reported being an imporvement over their 2000 paper. Still no
    comparisions with other background subtraction methods.
    

@inproceedings{Rymel2004,
title={Adaptive eigen-backgrounds for object detection},
author={Rymel, J. and Renno, J. and Greenhill, D. and Orwell, J. and Jones, GA},
booktitle={Image Processing, 2004. ICIP'04. 2004 International Conference on},
volume={3},
pages={1847--1850},
year={2004},
organization={IEEE}
}

	Adaptive eigenbackground with dynamic space sizing
	Adapt by adding to the covar matrix
	Nice comparison with standard eigenbackground, GMM and Wren et al. on PETS


@article{li2004incremental,
title={On incremental and robust subspace learning},
author={Li, Y.},
journal={Pattern recognition},
volume={37},
number={7},
pages={1509--1518},
year={2004},
publisher={Elsevier}
}

	This is a good paper
	
	Incremental and Robust PCA
	Previous work on Robustifying PCA was iterative and computationaly expensive - a drawback for online use
	They compare the statistics using PCA vs the raw real pixel statistics 
	Containts pseudo-code
	I like their experiment between their incremental robust pca and traditional pca, also a good description of Oliver et al
	
	2 main points, traditional PCA suffers from two limitations - computationally intensive, susceptable to outliers
	Good quote on how RPCA is to expensive for real time application


@INPROCEEDINGS{li2006fast, 
author={Ruonan Li and Yu Chen and Xudong Zhang}, 
booktitle={Image Processing, 2006 IEEE International Conference on}, 
title={Fast Robust Eigen-Background Updating for Foreground Detection}, 
year={2006}, 
month={oct.}, 
volume={}, 
number={}, 
pages={1833 -1836}, 
keywords={eigen-background updating;foreground object detection;object detection;}, 
ISSN={1522-4880},}

    Fast eigenbackground with update, some kind of robustness to learning foreground objects as background
    Has good referncing to the other subspace BGS papers
    Uses Torre RPCA in the update
    
    Looks like they combine RPCA with CCIPCA
    
    Has some pseudo code
    
    Combare with several IPCA BGS algorthims
    
    Seems to be the same as Li2004 (not the same Li)...


@article{Yamazaki2006,
title={Detection of moving objects by independent component analysis},
author={Yamazaki, M. and Xu, G. and Chen, Y.W.},
journal={Computer Vision--ACCV 2006},
pages={467--478},
year={2006},
publisher={Springer}
}

	BGS using ICA

@INPROCEEDINGS{Wang2007, 
author={Lu Wang and Lei Wang and Ming Wen and Qing Zhuo and Wenyuan Wang}, 
booktitle={Image Processing, 2007. ICIP 2007. IEEE International Conference on}, 
title={Background Subtraction using Incremental Subspace Learning}, 
year={2007}, 
month={16 2007-oct. 19}, 
volume={5}, 
number={}, 
pages={V -45 -V -48}, 
keywords={adaptive background modeling;computer vision;incremental subspace learning method;linear prediction model;object detection;sequential Karhunen-Loeve algorithm;subtraction approach;Karhunen-Loeve transforms;computer vision;learning (artificial intelligence);natural scenes;object detection;prediction theory;},  
ISSN={1522-4880},}

    Adaptive PCA or APCA background subtraction - essentially eigenbackground with update/learning


@inproceedings{Bucak2007,
title={Incremental non-negative matrix factorization for dynamic background modelling},
author={Bucak, S.S. and Gunsel, B. and Gursoy, O.},
booktitle={ICEIS 8th International Workshop on Pattern Recognition in Information Systems},
year={2007}
}

	BGS using Non Negative Matrix Factorization


@article{Bucak2009,
title={Incremental subspace learning via non-negative matrix factorization},
author={Bucak, S.S. and Gunsel, B.},
journal={Pattern recognition},
volume={42},
number={5},
pages={788--797},
year={2009},
publisher={Elsevier}
}

	BGS using Non Negative Matrix Factorization
		
@article{tsai2009independent,
  title={Independent component analysis-based background subtraction for indoor surveillance},
  author={Tsai, Du-Ming and Lai, Shia-Chih},
  journal={Image Processing, IEEE Transactions on},
  volume={18},
  number={1},
  pages={158--167},
  year={2009},
  publisher={IEEE}
}

@article{Dong2009,
Author = {Dong, Y. and Han, T. X. and DeSouza, G. N.},
ISSN = {13272314},
Journal = {International Journal of Knowledge Based Intelligent Engineering Systems},
Keywords = {ALGORITHMS, PIXELS, INVARIANT subspaces, ARITHMETIC -- Foundations, IMAGE processing, eigenspace, illumination invariance, LPCA, Multi-feature subspace},
Number = {1},
Pages = {31 - 41},
Title = {Illumination invariant foreground detection using multi-subspace learning.},
Volume = {14},
Year = {2010},}

    Precursor to Dong 2011, Local PCA - LPCA


@article{Dong2011,
title = "Adaptive learning of multi-subspace for foreground detection under illumination changes",
journal = "Computer Vision and Image Understanding",
volume = "115",
number = "1",
pages = "31 - 49",
year = "2011",
note = "",
issn = "1077-3142",
author = "Y. Dong and G.N. DeSouza",
keywords = "Multiple <span style='font-style: italic'>eigensubspace</span>",
keywords = "Local PCA",
keywords = "Incremental learning",
keywords = "Illumination invariance"}

    Possible "latest and greatest" of Eigenbackground/Subspace backgrround subtraction based approaches


@article{Tsai2009,
title={Independent component analysis-based background subtraction for indoor surveillance},
author={Tsai, D.M. and Lai, S.C.},
journal={Image Processing, IEEE Transactions on},
volume={18},
number={1},
pages={158--167},
year={2009},
publisher={IEEE}
}

	BGS using ICA	
	
@article{maddalena2008self,
  title={A self-organizing approach to background subtraction for visual surveillance applications},
  author={Maddalena, Lucia and Petrosino, Alfredo},
  journal={Image Processing, IEEE Transactions on},
  volume={17},
  number={7},
  pages={1168--1177},
  year={2008},
  publisher={IEEE}
}

@INPROCEEDINGS{Zhao2008, 
author={Youdong Zhao and Haifeng Gong and Liang Lin and Yunde Jia}, 
booktitle={Pattern Recognition, 2008. ICPR 2008. 19th International Conference on}, 
title={Spatio-temporal patches for night background modeling by subspace learning}, 
year={2008}, 
month={dec.}, 
volume={}, 
number={}, 
pages={1 -4}, 
keywords={lighting conditions;motion variance;night background modeling;online subspace learning;spatio-temporal information;spatio-temporal patches;video surveillance;learning (artificial intelligence);video surveillance;},  
ISSN={1051-4651},}

    Shorter version of Zhao 2012


@article{Zhao2012,
title = "Background modeling by subspace learning on spatio-temporal patches",
journal = "Pattern Recognition Letters",
volume = "33",
number = "9",
pages = "1134 - 1147",
year = "2012",
note = "",
issn = "0167-8655",
author = "Youdong Zhao and Haifeng Gong and Yunde Jia and Song-Chun Zhu",
keywords = "Visual surveillance",
keywords = "Background modeling",
keywords = "Spatio-temporal patch",
keywords = "Subspace learning" }

    Also possible latest and greatest of subspace BGS techniques
    
    Eigen "bricks" h x w x t, aka tiny 3d blocks. Report better performance of blocks compared to image patches.
    Do they still only return the foreground in dsicrete blocks though rather than pixel level?
    Performed a PCA to prove that background and illumination belongs to a small dimensional space while foregound 
    is in a high dimensional space by comparing the number of eigenvectors required to keep 95% variance of the set. 
    They use an adapted version of Weng2003 IPCA to incrementally build their subspaces. They extend the update rule to 
    only update appropriately with respect to foreground objects.
    Foreground detection is done through residual error of reconstruction.
    
    Claim method is not sensitive to initialization.



